{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary consideration on energy cut (*re-processed QE=0.20*)\n",
    "\n",
    "New consideration on energy cut only based on:\n",
    "- Number of PE detected (*NPE*)\n",
    "- Number of SiPM modules wt NPE>0 (*active slices*)\n",
    "\n",
    "First, we will focus on single Ar39 vs Muons.\n",
    "Then, we consider also other two *frequent* classes of 2, 3 Ar39 Pileups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "plt.rcParams['figure.figsize'] = [25, 15]\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe_from_files(dirin, fileprefix):\n",
    "    import glob\n",
    "    files = glob.glob(os.path.join(dirin, fileprefix))\n",
    "    print(\"[Info] Loading {} files wt prefix:\\n{}\".format(len(files), fileprefix))\n",
    "    df = pd.read_csv(files[0], comment='#', index_col=False)\n",
    "    for file in files[1:]:\n",
    "        print(\".\", end='')\n",
    "        dftmp = pd.read_csv(file, comment='#', index_col=False)\n",
    "        df = pd.concat([df, dftmp])\n",
    "    print(\"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Loading 100 files wt prefix:\n",
      "Snapshot1Ar39*\n",
      "...................................................................................................\n",
      "[Info] Loading 100 files wt prefix:\n",
      "Snapshot2Ar39*\n",
      "...................................................................................................\n",
      "[Info] Loading 100 files wt prefix:\n",
      "Snapshot3Ar39*\n",
      "...................................................................................................\n",
      "[Info] Loaded all 1,2,3 Ar39 Pileups in 102.28 seconds\n",
      "[Info] Loading 100 files wt prefix:\n",
      "SnapshotMuons*\n",
      "...................................................................................................\n",
      "[Info] Loaded all Muons in 1.84 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load Ar39\n",
    "init = time.time()\n",
    "dirin = os.path.join(\"..\", \"Data\", \"OutputProcessing\", \"Ar39_08_18_2020\", \"Ar39_Snapshots\")\n",
    "\n",
    "fileprefix = \"Snapshot1Ar39*\"\n",
    "df1ar39 = load_dataframe_from_files(dirin, fileprefix)\n",
    "\n",
    "fileprefix = \"Snapshot2Ar39*\"\n",
    "df2ar39 = load_dataframe_from_files(dirin, fileprefix)\n",
    "\n",
    "fileprefix = \"Snapshot3Ar39*\"\n",
    "df3ar39 = load_dataframe_from_files(dirin, fileprefix)\n",
    "\n",
    "print(\"[Info] Loaded all 1,2,3 Ar39 Pileups in {:.2f} seconds\".format(time.time() - init))\n",
    "\n",
    "# Load Muons\n",
    "init = time.time()\n",
    "dirin = os.path.join(\"..\", \"Data\", \"OutputProcessing\", \"Muons_08_18_2020\", \"Muons_Snapshots\")\n",
    "\n",
    "fileprefix = \"SnapshotMuons*\"\n",
    "dfmu = load_dataframe_from_files(dirin, fileprefix)\n",
    "print(\"[Info] Loaded all Muons in {:.2f} seconds\".format(time.time() - init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nr_active_slices(row):\n",
    "    return np.nonzero(row.to_numpy())[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inner_slices, n_outer_slices = 12, 20\n",
    "df1ar39[\"NActiveSlices\"] = df1ar39.iloc[:, 3:3+n_inner_slices+n_outer_slices].apply(lambda row: nr_active_slices(row), axis=1)\n",
    "df2ar39[\"NActiveSlices\"] = df2ar39.iloc[:, 3:3+n_inner_slices+n_outer_slices].apply(lambda row: nr_active_slices(row), axis=1)\n",
    "df3ar39[\"NActiveSlices\"] = df3ar39.iloc[:, 3:3+n_inner_slices+n_outer_slices].apply(lambda row: nr_active_slices(row), axis=1)\n",
    "dfmu[\"NActiveSlices\"] = dfmu.iloc[:, 3:3+n_inner_slices+n_outer_slices].apply(lambda row: nr_active_slices(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inner_slices, n_outer_slices = 12, 20\n",
    "df1ar39[\"NActiveSlices_outer\"] = df1ar39.iloc[:, 3+n_inner_slices:3+n_inner_slices+n_outer_slices].apply(lambda row: nr_active_slices(row), axis=1)\n",
    "df2ar39[\"NActiveSlices_outer\"] = df2ar39.iloc[:, 3+n_inner_slices:3+n_inner_slices+n_outer_slices].apply(lambda row: nr_active_slices(row), axis=1)\n",
    "df3ar39[\"NActiveSlices_outer\"] = df3ar39.iloc[:, 3+n_inner_slices:3+n_inner_slices+n_outer_slices].apply(lambda row: nr_active_slices(row), axis=1)\n",
    "dfmu[\"NActiveSlices_outer\"] = dfmu.iloc[:, 3+n_inner_slices:3+n_inner_slices+n_outer_slices].apply(lambda row: nr_active_slices(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various ROC, Mu vs 1Ar39\n",
    "** Why consider only 1 Ar39? **\n",
    "Given a decay rate of `3666 Hz` and a Detection Efficiency of `0.53035`, we expect a detection rate of `3666*.53035=1945 Hz`.\n",
    "Looking at the Poisson distribution to compute the probability of multiple decay \n",
    "\n",
    "To evaluate the various *simple* cut that can be performed on Number of PE detected (NPE) and Number of Active Slices (NAS), we plot several ROC curve, one for each feature on which we perform the cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5303515"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1ar39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tot NPE\n",
    "thresholds = list(range(50, -1, -1))\n",
    "tprs_tot_pe, fprs_tot_pe = [], []\n",
    "# Tot NAS\n",
    "tprs_tot_nas, fprs_tot_nas = [], []\n",
    "# Out NAS\n",
    "tprs_out_nas, fprs_out_nas = [], []\n",
    "for threshold in thresholds:\n",
    "    print(\".\", end=\"\")\n",
    "    # Tot NPE\n",
    "    tp = len(dfmu[dfmu.pedetected>=threshold])\n",
    "    fn = len(dfmu[dfmu.pedetected<threshold])\n",
    "    tn = len(df1ar39[df1ar39.pedetected<threshold])\n",
    "    fp = len(df1ar39[df1ar39.pedetected>=threshold])\n",
    "    tprs_tot_pe.append(tp / (tp+fn))\n",
    "    fprs_tot_pe.append(fp / (fp+tn))\n",
    "    # Tot NAS\n",
    "    tp = len(dfmu[dfmu.NActiveSlices>=threshold])\n",
    "    fn = len(dfmu[dfmu.NActiveSlices<threshold])\n",
    "    tn = len(df1ar39[df1ar39.NActiveSlices<threshold])\n",
    "    fp = len(df1ar39[df1ar39.NActiveSlices>=threshold])\n",
    "    tprs_tot_nas.append(tp / (tp+fn))\n",
    "    fprs_tot_nas.append(fp / (fp+tn))\n",
    "    # Out NAS\n",
    "    tp = len(dfmu[dfmu.NActiveSlices_outer>=threshold])\n",
    "    fn = len(dfmu[dfmu.NActiveSlices_outer<threshold])\n",
    "    tn = len(df1ar39[df1ar39.NActiveSlices_outer<threshold])\n",
    "    fp = len(df1ar39[df1ar39.NActiveSlices_outer>=threshold])\n",
    "    tprs_out_nas.append(tp / (tp+fn))\n",
    "    fprs_out_nas.append(fp / (fp+tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fprs_tot_pe, tprs_tot_pe, label=\"ROC Tot NPE\")\n",
    "plt.plot(fprs_tot_nas, tprs_tot_nas, label=\"ROC Tot NAS\")\n",
    "plt.plot(fprs_out_nas, tprs_out_nas, label=\"ROC Out NAS\")\n",
    "plt.plot(np.arange(50)/49, np.arange(50)/49, label=\"Baseline\")\n",
    "\n",
    "plt.vlines(0.03, ymin=0, ymax=1, label=\"FPR=3%\", color='r', linestyles='dashed')\n",
    "\n",
    "highlight_thresholds = [1, 2, 3, 4, 5]\n",
    "for threshold in highlight_thresholds:\n",
    "    id_threshold = thresholds.index(threshold)\n",
    "    plt.scatter(fprs_out_nas[id_threshold], tprs_out_nas[id_threshold], label=\"Out NAS={}\".format(threshold))\n",
    "    print(\"Cut Out NAS: Threshold={} => TPR=EFF={:.5f}, FPR={:.5f}\".format(threshold, tprs_out_nas[id_threshold], fprs_out_nas[id_threshold]))\n",
    "plt.xlabel(\"FPR = FP / (FP+TN)\")\n",
    "plt.ylabel(\"TPR = TP / (TP+FN)\")\n",
    "plt.title(\"ROC - Threshold in [0, 50]\")\n",
    "plt.legend()\n",
    "plt.xlim(-0.01, 1.01)\n",
    "plt.ylim(-0.01, 1.01)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
