{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import os, glob, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [25, 15]\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Loaded 138701 Ar39 decays, with maximum 60 PE detected\n",
      "[Info] Loaded 1241 Muons, with maximum 60 PE detected\n"
     ]
    }
   ],
   "source": [
    "# Load Ar39 Data\n",
    "import numpy as np\n",
    "\n",
    "ar39_file = os.path.join(\"..\", \"data\", \"Ar39_PE_in_15_60.csv\")\n",
    "muon_file = os.path.join(\"..\", \"data\", \"LowEnergyMuons_PE_in_15_60.csv\")\n",
    "\n",
    "ar39  = pd.read_csv(ar39_file, index_col=False)\n",
    "ar39 = ar39[ar39.columns[1:]]\n",
    "muons = pd.read_csv(muon_file, index_col=False)\n",
    "muons = muons[muons.columns[1:]]\n",
    "\n",
    "print(\"[Info] Loaded {} Ar39 decays, with maximum {} PE detected\".format(len(ar39), ar39.pedetected.max()))\n",
    "print(\"[Info] Loaded {} Muons, with maximum {} PE detected\".format(len(muons), muons.pedetected.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Muon Train 1000, Test 241\n",
      "[Info] Ar39 Train 38701, Test 100000\n"
     ]
    }
   ],
   "source": [
    "# Remove test data for later eval\n",
    "n_train_mu, n_train_ar = 241, 100000\n",
    "muons_test, muons_train = muons.iloc[:n_train_mu, :], muons.iloc[n_train_mu:, :]\n",
    "ar39_test, ar39_train = ar39.iloc[:n_train_ar, :], ar39.iloc[n_train_ar:, :]\n",
    "print(\"[Info] Muon Train {}, Test {}\".format(len(muons_train), len(muons_test)))\n",
    "print(\"[Info] Ar39 Train {}, Test {}\".format(len(ar39_train), len(ar39_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample_argon(ar39_df, number_of_instances=1000, augment_from_pe=35, augmentation_nr=5,\n",
    "                      skip_first_cols=2, nslices=72):\n",
    "    bins = np.linspace(0, 61, 62)\n",
    "    bin_cont, bin_edges, _ = plt.hist(ar39_df.pedetected, bins=bins, density=True, label=\"1Ar39\", edgecolor='w')\n",
    "    # compute the nr of samples for each PE value,\n",
    "    # to undersample ar39 keeping the same distribution\n",
    "    avail_instances_per_pe = np.array([len(ar39_df[ar39_df.pedetected==pe]) for pe in range(61)])\n",
    "    nr_ar_samples_per_pe = np.array(np.where(np.ceil(bin_cont*number_of_instances)<=avail_instances_per_pe, np.ceil(bin_cont*number_of_instances), 0), dtype=int)\n",
    "    # Introduce a small bias on instances with \"high\" PE value\n",
    "    # to avoid to have just a few samples (e.g. 30,40,50,60 PE)\n",
    "    scaled_ar39 = pd.DataFrame()\n",
    "    for pe in range(1, 61):\n",
    "        if pe > augment_from_pe:\n",
    "            nr_instances = augmentation_nr\n",
    "        else:\n",
    "            nr_instances = nr_ar_samples_per_pe[pe]\n",
    "        scaled_ar39 = pd.concat([scaled_ar39, ar39_df[ar39_df.pedetected==pe].iloc[:nr_instances]])\n",
    "    AA = scaled_ar39.iloc[:, skip_first_cols:skip_first_cols+nslices].to_numpy()\n",
    "    np.random.shuffle(AA)    # to avoid order by PE\n",
    "    return pd.DataFrame(AA)\n",
    "\n",
    "def augment_muons_by_roll(muon_df, augmentation_factor=1, skip_first_cols=2, nslices=72):\n",
    "    X = muon_df.iloc[:, skip_first_cols:skip_first_cols+nslices].to_numpy()\n",
    "    for roll in np.array(np.linspace(0, 72, augmentation_factor+1)[:-1], dtype='int'):\n",
    "        if roll==0:\n",
    "            XX = X\n",
    "        else:\n",
    "            XX = np.concatenate([XX, np.roll(X, roll, axis=1)])\n",
    "    return pd.DataFrame(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] The Augmented Muons dataset has 1000 instances\n",
      "[Info] The Scaled Ar39 dataset has 1054 instances\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Augment Muons\n",
    "muon_data = augment_muons_by_roll(muons_train, augmentation_factor=1)\n",
    "print(\"[Info] The Augmented Muons dataset has {} instances\".format(len(muon_data)))\n",
    "# Undersample Ar39\n",
    "ar39_data = undersample_argon(ar39_train, len(muon_data), augment_from_pe=35, augmentation_nr=5)\n",
    "print(\"[Info] The Scaled Ar39 dataset has {} instances\".format(len(ar39_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the std deviation of active slices based on NPE\n",
    "def stddev_idslices_fun(row):\n",
    "    # given an array of aquisitions, it return the std of activated slices\n",
    "    # it create a populaion of slice ids, and compute stddev on them\n",
    "    id_population = [item for id_list in [[i] * int(row.iloc[i]) for i in range(len(row))] for item in id_list]\n",
    "    if id_population:    # check if the list of slice ids is not empty\n",
    "        return np.std(id_population)\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "# function to produce quadrant-based features in a parametric way\n",
    "def produce_quadrant_features(df, nslices=72, nshiftings=4, quadrant_width=36):\n",
    "    # split aquisitions in K \"shifted\" quadrant\n",
    "    # by construction, there are 72 slices\n",
    "    # we set quadrant_width = nslices // 2 because \n",
    "    # we know that the spread is within 15 slices\n",
    "    shift = nslices // nshiftings   # derived\n",
    "    assert(len(df.columns) == nslices)\n",
    "    # create quadrants\n",
    "    df_quadrants = []\n",
    "    for i_shift in range(nshiftings):\n",
    "        assert(i_shift*shift < nslices)\n",
    "        quadrant = df.iloc[:, i_shift*shift:i_shift*shift + quadrant_width]\n",
    "        if i_shift*shift + quadrant_width >= nslices:\n",
    "            quadrant = pd.concat([quadrant, df.iloc[:, :i_shift*shift + quadrant_width - nslices]], axis=1)\n",
    "        df_quadrants.append(quadrant)\n",
    "    # compute stddev and meanPE for each quadrant\n",
    "    for quadrant in df_quadrants:\n",
    "        quadrant[\"stdslices\"] = quadrant.apply(stddev_idslices_fun, axis=1)\n",
    "        quadrant[\"meanpe\"] = quadrant.apply(lambda row: row[:quadrant_width].mean(), axis=1)\n",
    "    # aggregate the features in a single dataset\n",
    "    features = pd.DataFrame()\n",
    "    for i, quadrant in enumerate(df_quadrants):\n",
    "        features = pd.concat([features, quadrant[[\"stdslices\", \"meanpe\"]]], axis=1)\n",
    "    features.columns = [\"{}_{}\".format(col, j) for j in range(len(df_quadrants)) for col in [\"stdslices\", \"meanpe\"]]\n",
    "    return features\n",
    "\n",
    "# function to produce quad-based features for multiple configurations\n",
    "def produce_datasets_for_various_quandrant_features(muon_data, ar39_data, nshiftings, widths):\n",
    "    muon_datasets, ar39_1_datasets = [], []\n",
    "    for nshifting, width in zip(nshiftings, widths):\n",
    "        muon_datasets.append(produce_quadrant_features(muon_data, nshiftings=nshifting, quadrant_width=width))\n",
    "        print(\"[Info] Computed quadrant features wt nshifting={}, width={} for Muons\".format(nshifting, width))\n",
    "        ar39_1_datasets.append(produce_quadrant_features(ar39_data, nshiftings=nshifting, quadrant_width=width))\n",
    "        print(\"[Info] Computed quadrant features wt nshifting={}, width={} for Ar39\".format(nshifting, width))\n",
    "    return muon_datasets, ar39_1_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Computed quadrant features wt nshifting=1, width=72 for Muons\n",
      "[Info] Computed quadrant features wt nshifting=1, width=72 for Ar39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luigi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/luigi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Computed quadrant features wt nshifting=2, width=54 for Muons\n",
      "[Info] Computed quadrant features wt nshifting=2, width=54 for Ar39\n",
      "[Info] Computed quadrant features wt nshifting=4, width=36 for Muons\n",
      "[Info] Computed quadrant features wt nshifting=4, width=36 for Ar39\n"
     ]
    }
   ],
   "source": [
    "nshiftings = [1, 2, 4]\n",
    "widths = [72, 54, 36]\n",
    "muons_datasets, ar39_1_datasets = produce_datasets_for_various_quandrant_features(muon_data, ar39_data, nshiftings, widths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize DTree on raw input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Tune criterion\n",
      "{'criterion': 'entropy'}\n",
      "0.6864936707872371\n",
      "\n",
      "[Info] Tune Depth, Min Samples leaf\n",
      "{'max_depth': 2, 'min_samples_leaf': 1}\n",
      "0.7014291325255562\n",
      "\n",
      "[Info] 5 fold CV\n",
      "Results: [0.8        0.63414634 0.66315789 0.68965517 0.75      ]\n",
      "Mean Score: 0.70739188172281, Std Dev: 0.060046416951626824\n",
      "Elapsed time 4.771615743637085\n"
     ]
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import time\n",
    "\n",
    "init = time.time()\n",
    "\n",
    "muon_features, ar39_features = muon_data, ar39_data\n",
    "# Prepare data for training\n",
    "muon_features[\"y\"] = 1\n",
    "ar39_features[\"y\"] = 0\n",
    "data = pd.concat([muon_features, ar39_features], axis=0)\n",
    "X, y = data.iloc[:, :-1], data.iloc[:, -1]\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"[Info] Tune criterion\")\n",
    "parameters = {'criterion': ['gini', 'entropy']}        \n",
    "\n",
    "# Conduct Parameter Optmization With Pipeline\n",
    "# Create a grid search object\n",
    "clf = GridSearchCV(DecisionTreeClassifier(max_depth=8, min_samples_leaf=1), \n",
    "                   param_grid = parameters, \n",
    "                   scoring='precision', n_jobs=2, cv=5)\n",
    "\n",
    "# Fit the grid search\n",
    "clf.fit(X, y)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n",
    "\n",
    "print(\"\\n[Info] Tune Depth, Min Samples leaf\")\n",
    "parameters = {'max_depth': [2, 4, 6, 8, 12],\n",
    "             'min_samples_leaf': [1, 10, 30, 50, 100]}        \n",
    "\n",
    "# Conduct Parameter Optmization With Pipeline\n",
    "# Create a grid search object\n",
    "clf = GridSearchCV(DecisionTreeClassifier(criterion='entropy'), \n",
    "                   param_grid = parameters, \n",
    "                   scoring='precision', n_jobs=2, cv=5)\n",
    "\n",
    "# Fit the grid search\n",
    "clf.fit(X, y)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n",
    "\n",
    "print(\"\\n[Info] 5 fold CV\")\n",
    "# Use Cross Validation To Evaluate Model\n",
    "CV_Result = cross_val_score(clf, X, y, cv=5, scoring='precision')\n",
    "print(\"Results: {}\".format(CV_Result))\n",
    "print(\"Mean Score: {}, Std Dev: {}\".format(CV_Result.mean(), CV_Result.std()))\n",
    "\n",
    "print(\"Elapsed time {}\".format(time.time() - init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize DTree on quadrant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Dataset 0\n",
      "  [Info] Tune criterion\n",
      "  [Info] Tune Depth, Min Samples leaf\n",
      "  [Result] Best model: criterion: entropy, depth: 2, min samples leaf: 1\n",
      "  [Eval 5CV] Mean Score: 0.8195, Std Dev: 0.0233\n",
      "\n",
      "  [Info] Elapsed time 0.36\n",
      "\n",
      "[Info] Dataset 1\n",
      "  [Info] Tune criterion\n",
      "  [Info] Tune Depth, Min Samples leaf\n",
      "  [Result] Best model: criterion: entropy, depth: 2, min samples leaf: 1\n",
      "  [Eval 5CV] Mean Score: 0.8287, Std Dev: 0.0237\n",
      "\n",
      "  [Info] Elapsed time 1.03\n",
      "\n",
      "[Info] Dataset 2\n",
      "  [Info] Tune criterion\n",
      "  [Info] Tune Depth, Min Samples leaf\n",
      "  [Result] Best model: criterion: gini, depth: 2, min samples leaf: 1\n",
      "  [Eval 5CV] Mean Score: 0.8030, Std Dev: 0.0284\n",
      "\n",
      "  [Info] Elapsed time 1.74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "init = time.time()\n",
    "\n",
    "models = []\n",
    "for i, (muon_features, ar39_features) in enumerate(zip(muons_datasets, ar39_1_datasets)):\n",
    "    print(\"[Info] Dataset {}\".format(i))\n",
    "    # Prepare data for training\n",
    "    muon_features[\"y\"] = 1\n",
    "    ar39_features[\"y\"] = 0\n",
    "    data = pd.concat([muon_features, ar39_features], axis=0)\n",
    "    X, y = data.iloc[:, :-1], data.iloc[:, -1]\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    print(\"  [Info] Tune criterion\")\n",
    "    parameters = {'criterion': ['gini', 'entropy']}        \n",
    "\n",
    "    # Conduct Parameter Optmization With Pipeline\n",
    "    # Create a grid search object\n",
    "    clf = GridSearchCV(DecisionTreeClassifier(max_depth=8, min_samples_leaf=1), \n",
    "                       param_grid = parameters, \n",
    "                       scoring='precision', n_jobs=2, cv=5)\n",
    "\n",
    "    # Fit the grid search\n",
    "    clf.fit(X, y)\n",
    "    best_criterion = clf.best_params_[\"criterion\"]\n",
    "\n",
    "\n",
    "    print(\"  [Info] Tune Depth, Min Samples leaf\")\n",
    "    parameters = {'max_depth': [2, 4, 6, 8, 12],\n",
    "                 'min_samples_leaf': [1, 10, 30, 50, 100]}        \n",
    "\n",
    "    # Conduct Parameter Optmization With Pipeline\n",
    "    # Create a grid search object\n",
    "    clf = GridSearchCV(DecisionTreeClassifier(criterion='entropy'), \n",
    "                       param_grid = parameters, \n",
    "                       scoring='precision', n_jobs=2, cv=5)\n",
    "\n",
    "    # Fit the grid search\n",
    "    clf.fit(X, y)\n",
    "    best_depth = clf.best_params_[\"max_depth\"]\n",
    "    best_minsamples = clf.best_params_[\"min_samples_leaf\"]\n",
    "\n",
    "    # Use Cross Validation To Evaluate Model\n",
    "    print(\"  [Result] Best model: criterion: {}, depth: {}, min samples leaf: {}\".format(best_criterion, best_depth, best_minsamples))\n",
    "    clf = DecisionTreeClassifier(criterion=best_criterion, max_depth=best_depth, min_samples_leaf=best_minsamples)\n",
    "    clf.fit(X, y)\n",
    "    models.append(clf)\n",
    "    CV_Result = cross_val_score(clf, X, y, cv=5, scoring='precision')\n",
    "    print(\"  [Eval 5CV] Mean Score: {:.4f}, Std Dev: {:.4f}\".format(CV_Result.mean(), CV_Result.std()))\n",
    "\n",
    "    print(\"\\n  [Info] Elapsed time {:.2f}\".format(time.time() - init))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix as cv\n",
    "\n",
    "def test_model(muon_features, ar39_features, model, model_name):\n",
    "    data_template    = \"[Info] Dataset with {} features\"\n",
    "    model_template   = \"[Info] Model: {}\"\n",
    "    cm_template  = \"[Result] Conf. Matrix: TN: {}, FP: {}, FN: {}, TP: {} | TPR: {:.2f}%, FPR: {:.2f}%\\n\"\n",
    "    result_template  = \"[Result] {}: Accuracy: {:.3f}, Precision: {:.3f}, Recall: {:.3f}, F1: {:.3f}\\n\"\n",
    "\n",
    "    print(data_template.format(len(muon_features.columns)))\n",
    "    print(model_template.format(model_name))\n",
    "    # Prepare data for training\n",
    "    muon_features[\"y\"] = 1\n",
    "    ar39_features[\"y\"] = 0\n",
    "    # data preparation\n",
    "    data = pd.concat([muon_features, ar39_features], axis=0)\n",
    "    X, y = data.iloc[:, :-1], data.iloc[:, -1]\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    # evaluation\n",
    "    y_pred = model.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    tn, fp, fn, tp = cv(y, y_pred).ravel()\n",
    "    #print(result_template.format(\"Test({} Mu, {} Ar)\".format(len(muon_features), len(ar39_1_features)),\n",
    "    #                            accuracy, precision, recall, f1))    \n",
    "    tpr, fpr = recall*100, fp/(fp+tn)*100\n",
    "    print(cm_template.format(tn, fp, fn, tp, tpr, fpr))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Computed quadrant features wt nshifting=1, width=72 for Muons\n",
      "[Info] Computed quadrant features wt nshifting=1, width=72 for Ar39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luigi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/luigi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Computed quadrant features wt nshifting=2, width=54 for Muons\n",
      "[Info] Computed quadrant features wt nshifting=2, width=54 for Ar39\n",
      "[Info] Computed quadrant features wt nshifting=4, width=36 for Muons\n",
      "[Info] Computed quadrant features wt nshifting=4, width=36 for Ar39\n"
     ]
    }
   ],
   "source": [
    "# prepare test data\n",
    "skip_first_cols, nslices = 2, 72\n",
    "muon_test_data = pd.DataFrame(muons_test.iloc[:, skip_first_cols:skip_first_cols+nslices].to_numpy())\n",
    "ar39_test_data = pd.DataFrame(ar39_test.iloc[:, skip_first_cols:skip_first_cols+nslices].to_numpy())\n",
    "# prepare datasets\n",
    "prom_shiftings = [1, 2, 4]\n",
    "prom_widths = [72, 54, 36]\n",
    "muons_test_datasets, ar39_1_test_datasets = produce_datasets_for_various_quandrant_features(muon_test_data, ar39_test_data, prom_shiftings, prom_widths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Dataset with 3 features\n",
      "[Info] Model: DTree\n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': None, 'splitter': 'best'}\n",
      "[Result] Conf. Matrix: TN: 45457, FP: 4543, FN: 93, TP: 148 | TPR: 61.41%, FPR: 9.09%\n",
      "\n",
      "[Info] Dataset with 5 features\n",
      "[Info] Model: DTree\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': None, 'splitter': 'best'}\n",
      "[Result] Conf. Matrix: TN: 44855, FP: 5145, FN: 95, TP: 146 | TPR: 60.58%, FPR: 10.29%\n",
      "\n",
      "[Info] Dataset with 9 features\n",
      "[Info] Model: DTree\n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 10, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': None, 'splitter': 'best'}\n",
      "[Result] Conf. Matrix: TN: 45350, FP: 4650, FN: 99, TP: 142 | TPR: 58.92%, FPR: 9.30%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model, muon_features, ar39_1_features in zip(models, muons_test_datasets, ar39_1_test_datasets):\n",
    "    test_model(muon_features, ar39_1_features, model, \"DTree\\n{}\".format(model.get_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
