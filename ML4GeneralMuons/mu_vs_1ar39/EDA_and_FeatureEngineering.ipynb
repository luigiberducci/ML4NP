{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import os, glob, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "plt.rcParams['figure.figsize'] = [25, 15]\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load data from multiple input files\n",
    "def load_dataframe_from_files(dirin, fileprefix):\n",
    "    import glob\n",
    "    files = glob.glob(os.path.join(dirin, fileprefix))\n",
    "    print(\"[Info] Loading {} files wt prefix:\\n{}\".format(len(files), fileprefix))\n",
    "    df = pd.read_csv(files[0], comment='#', index_col=False)\n",
    "    for file in files[1:]:\n",
    "        print(\".\", end='')\n",
    "        dftmp = pd.read_csv(file, comment='#', index_col=False)\n",
    "        df = pd.concat([df, dftmp])\n",
    "    print(\"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Loading 1 files wt prefix:\n",
      "Ar39_1Pileup_2000000.csv\n",
      "\n",
      "[Info] The Ar39 decays have maximum 51 PE detected\n"
     ]
    }
   ],
   "source": [
    "# Load Ar39 Data\n",
    "import numpy as np\n",
    "\n",
    "dirin = \"../data/Ar39/dataset_all1ar39\"    # where to write combined datasets\n",
    "infilename = \"Ar39_1Pileup_2000000.csv\"\n",
    "\n",
    "df_ar39 = load_dataframe_from_files(dirin, infilename)\n",
    "maxPEar39 = df_ar39.pedetected.max()\n",
    "print(\"[Info] The Ar39 decays have maximum {} PE detected\".format(maxPEar39))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full cylinder features\n",
    "Considering the 72 slices, we propose the following features:\n",
    "#### Features on Detection:\n",
    "- NPE: total number of PE detected\n",
    "- NActiveSlices: total number of slices wt NPE>0\n",
    "- MeanNPE: mean PE detected\n",
    "- StdNPE: std deviation of NPEs\n",
    "\n",
    "#### Features on Spatial Distribution:\n",
    "- Range: difference between highest slice ID and lowet slice ID\n",
    "- Var: variance of IDs (ids replicated for NPE)\n",
    "- Std: std deviation of IDs (ids replicated for NPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slices = df_ar39.iloc[:, 2:]\n",
    "del df_ar39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute npe\n",
    "# NUMPY\n",
    "t = time.time()\n",
    "for i, row in df_slices.iloc[0:10000, :].iterrows():\n",
    "    row.to_numpy().sum()\n",
    "print(\"Time wt Numpy: {:5f} sec\".format(time.time() - t))\n",
    "\n",
    "# PYTHON\n",
    "t = time.time()\n",
    "for i, row in df_slices.iloc[0:10000, :].iterrows():\n",
    "    row.sum()\n",
    "print(\"Time wt Pandas: {:5f} sec\".format(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute max detection\n",
    "t = time.time()\n",
    "for i, row in df_slices.iloc[0:10000, :].iterrows():\n",
    "    row.to_numpy().max()\n",
    "print(\"Time wt Numpy: {:5f} sec\".format(time.time() - t))\n",
    "\n",
    "t = time.time()\n",
    "for i, row in df_slices.iloc[0:10000, :].iterrows():\n",
    "    row.max()\n",
    "print(\"Time wt Pandas: {:5f} sec\".format(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean detection\n",
    "t = time.time()\n",
    "for i, row in df_slices.iloc[0:10000, :].iterrows():\n",
    "    np.mean(row.to_numpy())\n",
    "print(\"Time wt Numpy: {:5f} sec\".format(time.time() - t))\n",
    "\n",
    "t = time.time()\n",
    "for i, row in df_slices.iloc[0:10000, :].iterrows():\n",
    "    row.mean()\n",
    "print(\"Time wt Pandas: {:5f} sec\".format(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute std detection\n",
    "t = time.time()\n",
    "for i, row in df_slices.iloc[0:10000, :].iterrows():\n",
    "    np.std(row.to_numpy())\n",
    "print(\"Time wt Numpy: {:5f} sec\".format(time.time() - t))\n",
    "\n",
    "t = time.time()\n",
    "for i, row in df_slices.iloc[0:10000, :].iterrows():\n",
    "    row.std()\n",
    "print(\"Time wt Pandas: {:5f} sec\".format(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute nr active slices\n",
    "# NUMPY\n",
    "t = time.time()\n",
    "for i, row in df_slices.iloc[0:10000, :].iterrows():\n",
    "    np.nonzero(row.to_numpy())[0].shape[0]\n",
    "print(\"Time wt Numpy: {:5f} sec\".format(time.time() - t))\n",
    "\n",
    "# PYTHON\n",
    "t = time.time()\n",
    "for i, row in df_slices.iloc[0:10000, :].iterrows():\n",
    "    len(row[row>0])\n",
    "print(\"Time wt Pandas: {:5f} sec\".format(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute range\n",
    "t = time.time()\n",
    "for i, row in df_slices.iloc[0:10000, :].iterrows():\n",
    "    np.where(row.to_numpy()>0)[0][-1] - np.where(row.to_numpy()>0)[0][0]\n",
    "print(\"Time wt Numpy: {:5f} sec\".format(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute var of ids\n",
    "t = time.time()\n",
    "for i, row in df_slices.iloc[0:10000, :].iterrows():\n",
    "    rownp = row.to_numpy()\n",
    "    np.var(np.repeat(np.argwhere(rownp>0), rownp[rownp>0]))\n",
    "print(\"Time wt Numpy: {:5f} sec\".format(time.time() - t))\n",
    "\n",
    "t = time.time()\n",
    "for i, row in df_slices.iloc[0:10000, :].iterrows():\n",
    "    id_population = [item for id_list in [[i] * int(row.iloc[i]) for i in range(len(row))] for item in id_list]\n",
    "    np.var(id_population)\n",
    "print(\"Time wt Pandas: {:5f} sec\".format(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute std dev of ids\n",
    "t = time.time()\n",
    "for i, row in df_slices.iloc[0:10000, :].iterrows():\n",
    "    rownp = row.to_numpy()\n",
    "    np.std(np.repeat(np.argwhere(rownp>0), rownp[rownp>0]))\n",
    "print(\"Time wt Numpy: {:5f} sec\".format(time.time() - t))\n",
    "\n",
    "t = time.time()\n",
    "for i, row in df_slices.iloc[0:10000, :].iterrows():\n",
    "    id_population = [item for id_list in [[i] * int(row.iloc[i]) for i in range(len(row))] for item in id_list]\n",
    "    np.std(id_population)\n",
    "print(\"Time wt Pandas: {:5f} sec\".format(time.time() - t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadrant-based Features\n",
    "The above features can be computed for quadrants, where the *quadrant* is a subsequence of slices. Basically, we can decompose the cylinder in a certain number of quadrants (eventually overlapped)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time wt Pandas: 0.160734 sec\n",
      "Time wt Numpy: 0.174299 sec\n"
     ]
    }
   ],
   "source": [
    "nslices=72\n",
    "nshiftings=4\n",
    "quadrant_width=36\n",
    "\n",
    "t = time.time()\n",
    "shift = nslices // nshiftings   # derived\n",
    "df_quadrants_pd = []\n",
    "for i_shift in range(nshiftings):\n",
    "    assert(i_shift*shift < nslices)\n",
    "    quadrant = df_slices.iloc[:, i_shift*shift:i_shift*shift + quadrant_width]\n",
    "    if i_shift*shift + quadrant_width >= nslices:\n",
    "        quadrant = pd.concat([quadrant, df_slices.iloc[:, :i_shift*shift + quadrant_width - nslices]], axis=1)\n",
    "    df_quadrants_pd.append(quadrant)\n",
    "print(\"Time wt Pandas: {:5f} sec\".format(time.time() - t))\n",
    "\n",
    "t = time.time()\n",
    "df_quadrants = []\n",
    "df_numpy = df_slices.to_numpy()\n",
    "for i_shift in range(nshiftings):\n",
    "    assert(i_shift*shift < nslices)\n",
    "    quadrant = df_numpy[:, i_shift*shift:i_shift*shift + quadrant_width]\n",
    "    if i_shift*shift + quadrant_width >= nslices:\n",
    "        quadrant = np.concatenate([quadrant, df_numpy[:, :i_shift*shift + quadrant_width - nslices]], axis=1)\n",
    "    df_quadrants.append(quadrant)\n",
    "print(\"Time wt Numpy: {:5f} sec\".format(time.time() - t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quadrants_pd[0].to_numpy() == df_quadrants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numpy[:, 0:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
